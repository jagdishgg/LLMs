{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055fa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b41bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28229ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d04d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b19e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"D:/Python/AI_POC/New_python/defog\"\n",
    "model_name = \"defog/sqlcoder\"\n",
    "off_load_path= r\"D:/Python/AI_POC/New_python/defog/offload\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534905e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6c4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForCausalLM.from_pretrained(    model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d856b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d87af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6516a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2819a4f34a9b413c9c35bfa3720da4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # load_in_8bit=True,\n",
    "    load_in_4bit=False,\n",
    "    #device_map=\"auto\",\n",
    "    use_cache=True,\n",
    "    offload_folder= off_load_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad03a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Total Entry transactions for date 12th July 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad3d10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Instructions:\n",
    "Your task is convert a question into a SQL query, given a Postgres database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\n",
    "- When creating a ratio, always cast the numerator as float\n",
    "\n",
    "### Input:\n",
    "Generate a SQL query that answers the questioq `{question}`.\n",
    "This query will run on a database whose schema is represented in this string:\n",
    "CREATE TABLE ENEX_MASTER  --table for entry exit \n",
    "(\n",
    "  EMA_SEQ                  NUMBER(5), -- Unique ID for each SPM_PERSON_NO\n",
    "  SPM_PERSON_NO            NUMBER(12), --Unique number per each person\n",
    "  NAT_CODE                 NUMBER(3),\n",
    "  EBO_CODE                 NUMBER(4),\n",
    "  ETT_CODE                 NUMBER(3),\n",
    "  SFU_CODE                 NUMBER(2)          ,\n",
    "  SDE_CODE                 NUMBER(3),\n",
    "  EMA_TYPE                 NUMBER(1), ema_type 1 is entry, 2 is exit \n",
    "  EMA_YEAR                 NUMBER(4),\n",
    "  EMA_DATE                 DATE, --entry or exit date based on ema_type\n",
    "  EMA_CREATED_BY           VARCHAR2(10 BYTE), --if ema_created is E$GATE THEN Egate transaction else Eborder\n",
    "  EMA_DEL_FLAG             NUMBER(1)          ,\n",
    "  EMA_FLIGHT_TRIP_NO       VARCHAR2(10 BYTE),\n",
    "  EMA_AIR_SHIP_CODE        NUMBER(10),\n",
    "  AIRPORT_CODE             VARCHAR2(3 BYTE)\n",
    "  );\n",
    "\n",
    "CREATE TABLE NATIONALITIES  --table for nationalities lookup\n",
    "(\n",
    "  CODE                NUMBER(3)        ,\n",
    "  COUNTRY             VARCHAR2(50 BYTE),\n",
    "  COUNTRY_ENG         VARCHAR2(50 BYTE),\n",
    "  SHORT_DESC          VARCHAR2(3 BYTE)\n",
    "  );\n",
    "\n",
    "CREATE TABLE PERSON_MASTER   --table for person details\n",
    "(\n",
    "  SPM_PERSON_NO            NUMBER(12)          ,--foreign key to column SPM_PERSON_NO  in enex_master\n",
    "  NAT_CODE_CURR_NAT        NUMBER(3)           , --This is Nationality of person\n",
    "  SPM_FULL_ANAME           VARCHAR2(80 BYTE), --full name of passenger in arabic\n",
    "  SPM_FULL_ENAME           VARCHAR2(80 BYTE),--full name of passenger in english\n",
    "  SPM_DOB                  DATE,  --date of birth of passenger\n",
    "  SPM_GENDER               NUMBER(1), --gender of passenger \n",
    "  SPM_NATIONAL_ID          VARCHAR2(20 BYTE)\n",
    ";\n",
    "\n",
    "create table ENEX_BORDER  --table for border types\n",
    "(\n",
    "ebo_code number ,\n",
    "ebo_type number , ---ebo_type =1 is Land Border,ebo_type=2 is Sea port,ebo_type= 3 it is Airport \n",
    "ebo_desc varchar2(80 byte)\n",
    ");\n",
    "\n",
    "-- ENEX_MASTER.SPM_PERSON_NO can be joined with PERSON_MASTER.SPM_PERSON_NO\n",
    "-- PERSON_MASTER.NAT_CODE_CURR_NAT can be joined with NATIONALITIES.code\n",
    "-- ENEX_MASTER.ebo_code can be joined with ENEX_border.ebo_code\n",
    "--ebo_type =1 is Land Border\n",
    "--ebo_type=2 is Sea port\n",
    "--ebo_type= 3 it is Airport \n",
    "--SPM_GENDER =0 it is female\n",
    "--SPM_GENDER = 1 it is male\n",
    "\n",
    "### Response:\n",
    "Based on your instructions, here is the SQL query I have generated to answer the question `{question}`:\n",
    "```sql\n",
    "\"\"\".format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0eeb63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5993551f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2811503374.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\a-jagdish\\AppData\\Local\\Temp\\10\\ipykernel_22036\\2811503374.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    **inputs,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "#inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "#generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    num_beams=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5adf533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id,\n",
    "    #max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    num_beams=5,\n",
    "    max_length=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307cba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6248d009",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\10\\ipykernel_22036\\2177206102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# empty cache so that you do generate more results w/o memory crashing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# particularly important on Colab – memory management is much more straightforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# when running on an inference service\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# empty cache so that you do generate more results w/o memory crashing\n",
    "# particularly important on Colab – memory management is much more straightforward\n",
    "# when running on an inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebf56d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sum(enex_master.ema_seq) AS total_entry_transactions\n",
      "FROM   enex_master\n",
      "WHERE  enex_master.ema_date = '2023-07-12'\n",
      "   and enex_master.ema_type = 1;\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19980d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30165e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Total Entry transactions OF Seaport for date 12th July 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3af106b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(\n",
    "    **inputs,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=eos_token_id,\n",
    "    pad_token_id=eos_token_id,\n",
    "    #max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    num_beams=5,\n",
    "    max_length=1200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b09982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28ee4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sum(enex_master.ema_seq) AS total_entry_transactions\n",
      "FROM   enex_master join enex_border on enex_master.ebo_code = enex_border.ebo_code\n",
      "WHERE  enex_master.ema_date = '2023-07-12'\n",
      "   and enex_border.ebo_type = 2;\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e572eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"### Instructions:\\nYour task is convert a question into a SQL query, given a Postgres database schema.\\nAdhere to these rules:\\n- **Deliberately go through the question and database schema word by word** to appropriately answer the question\\n- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\\n- When creating a ratio, always cast the numerator as float\\n\\n### Input:\\nGenerate a SQL query that answers the questioq `Total Entry transactions OF Seaport for date 12th July 2023`.\\nThis query will run on a database whose schema is represented in this string:\\nCREATE TABLE ENEX_MASTER  --table for entry exit \\n(\\n  EMA_SEQ                  NUMBER(5), -- Unique ID for each SPM_PERSON_NO\\n  SPM_PERSON_NO            NUMBER(12), --Unique number per each person\\n  NAT_CODE                 NUMBER(3),\\n  EBO_CODE                 NUMBER(4),\\n  ETT_CODE                 NUMBER(3),\\n  SFU_CODE                 NUMBER(2)         ,\\n  SDE_CODE                 NUMBER(3),\\n  EMA_TYPE                 NUMBER(1), ema_type 1 is entry, 2 is exit \\n  EMA_YEAR                 NUMBER(4),\\n  EMA_DATE                 DATE, --entry or exit date based on ema_type\\n  EMA_CREATED_BY           VARCHAR2(10 BYTE), --if ema_created is E$GATE THEN Egate transaction else Eborder\\n  EMA_DEL_FLAG             NUMBER(1)         ,\\n  EMA_FLIGHT_TRIP_NO       VARCHAR2(10 BYTE),\\n  EMA_AIR_SHIP_CODE        NUMBER(10),\\n  AIRPORT_CODE             VARCHAR2(3 BYTE)\\n  );\\n\\nCREATE TABLE NATIONALITIES  --table for nationalities lookup\\n(\\n  CODE                NUMBER(3)       ,\\n  COUNTRY             VARCHAR2(50 BYTE),\\n  COUNTRY_ENG         VARCHAR2(50 BYTE),\\n  SHORT_DESC          VARCHAR2(3 BYTE)\\n  );\\n\\nCREATE TABLE PERSON_MASTER   --table for person details\\n(\\n  SPM_PERSON_NO            NUMBER(12)         ,--foreign key to column SPM_PERSON_NO  in enex_master\\n  NAT_CODE_CURR_NAT        NUMBER(3)          , --This is Nationality of person\\n  SPM_FULL_ANAME           VARCHAR2(80 BYTE),\\n  SPM_FULL_ENAME           VARCHAR2(80 BYTE),\\n  SPM_DOB                  DATE,\\n  SPM_GENDER               NUMBER(1),\\n  SPM_NATIONAL_ID          VARCHAR2(20 BYTE)\\n;\\n\\ncreate table ENEX_BORDER  --table for border types\\n(\\nebo_code number,\\nebo_type number, ---ebo_type =1 is Land Border,ebo_type=2 is Sea port,ebo_type= 3 it is Airport \\nebo_desc varchar2(80 byte)\\n);\\n\\n-- ENEX_MASTER.SPM_PERSON_NO can be joined with PERSON_MASTER.SPM_PERSON_NO\\n-- PERSON_MASTER.NAT_CODE_CURR_NAT can be joined with NATIONALITIES.code\\n-- ENEX_MASTER.ebo_code can be joined with ENEX_border.ebo_code\\n--ebo_type =1 is Land Border\\n--ebo_type=2 is Sea port\\n--ebo_type= 3 it is Airport \\n\\n### Response:\\nBased on your instructions, here is the SQL query I have generated to answer the question `Total Entry transactions OF Seaport for date 12th July 2023`:\\n```sql\\nSELECT sum(enex_master.ema_seq) AS total_entry_transactions\\nFROM   enex_master join enex_border on enex_master.ebo_code = enex_border.ebo_code\\nWHERE  enex_master.ema_date = '2023-07-12'\\n   and enex_border.ebo_type = 2;\\n```\"]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd401dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Total Entry transactions OF Seaport of Female passengers for date 12th July 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a80ff1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sum(enex_master.ema_seq) AS total_entry_transactions\n",
      "FROM   enex_master join enex_border on enex_master.ebo_code = enex_border.ebo_code\n",
      "WHERE  enex_master.ema_date = '2023-07-12'\n",
      "   and enex_border.ebo_type = 2;\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "318085a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"### Instructions:\\nYour task is convert a question into a SQL query, given a Postgres database schema.\\nAdhere to these rules:\\n- **Deliberately go through the question and database schema word by word** to appropriately answer the question\\n- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\\n- When creating a ratio, always cast the numerator as float\\n\\n### Input:\\nGenerate a SQL query that answers the questioq `Total Entry transactions OF Seaport for date 12th July 2023`.\\nThis query will run on a database whose schema is represented in this string:\\nCREATE TABLE ENEX_MASTER  --table for entry exit \\n(\\n  EMA_SEQ                  NUMBER(5), -- Unique ID for each SPM_PERSON_NO\\n  SPM_PERSON_NO            NUMBER(12), --Unique number per each person\\n  NAT_CODE                 NUMBER(3),\\n  EBO_CODE                 NUMBER(4),\\n  ETT_CODE                 NUMBER(3),\\n  SFU_CODE                 NUMBER(2)         ,\\n  SDE_CODE                 NUMBER(3),\\n  EMA_TYPE                 NUMBER(1), ema_type 1 is entry, 2 is exit \\n  EMA_YEAR                 NUMBER(4),\\n  EMA_DATE                 DATE, --entry or exit date based on ema_type\\n  EMA_CREATED_BY           VARCHAR2(10 BYTE), --if ema_created is E$GATE THEN Egate transaction else Eborder\\n  EMA_DEL_FLAG             NUMBER(1)         ,\\n  EMA_FLIGHT_TRIP_NO       VARCHAR2(10 BYTE),\\n  EMA_AIR_SHIP_CODE        NUMBER(10),\\n  AIRPORT_CODE             VARCHAR2(3 BYTE)\\n  );\\n\\nCREATE TABLE NATIONALITIES  --table for nationalities lookup\\n(\\n  CODE                NUMBER(3)       ,\\n  COUNTRY             VARCHAR2(50 BYTE),\\n  COUNTRY_ENG         VARCHAR2(50 BYTE),\\n  SHORT_DESC          VARCHAR2(3 BYTE)\\n  );\\n\\nCREATE TABLE PERSON_MASTER   --table for person details\\n(\\n  SPM_PERSON_NO            NUMBER(12)         ,--foreign key to column SPM_PERSON_NO  in enex_master\\n  NAT_CODE_CURR_NAT        NUMBER(3)          , --This is Nationality of person\\n  SPM_FULL_ANAME           VARCHAR2(80 BYTE),\\n  SPM_FULL_ENAME           VARCHAR2(80 BYTE),\\n  SPM_DOB                  DATE,\\n  SPM_GENDER               NUMBER(1),\\n  SPM_NATIONAL_ID          VARCHAR2(20 BYTE)\\n;\\n\\ncreate table ENEX_BORDER  --table for border types\\n(\\nebo_code number,\\nebo_type number, ---ebo_type =1 is Land Border,ebo_type=2 is Sea port,ebo_type= 3 it is Airport \\nebo_desc varchar2(80 byte)\\n);\\n\\n-- ENEX_MASTER.SPM_PERSON_NO can be joined with PERSON_MASTER.SPM_PERSON_NO\\n-- PERSON_MASTER.NAT_CODE_CURR_NAT can be joined with NATIONALITIES.code\\n-- ENEX_MASTER.ebo_code can be joined with ENEX_border.ebo_code\\n--ebo_type =1 is Land Border\\n--ebo_type=2 is Sea port\\n--ebo_type= 3 it is Airport \\n\\n### Response:\\nBased on your instructions, here is the SQL query I have generated to answer the question `Total Entry transactions OF Seaport for date 12th July 2023`:\\n```sql\\nSELECT sum(enex_master.ema_seq) AS total_entry_transactions\\nFROM   enex_master join enex_border on enex_master.ebo_code = enex_border.ebo_code\\nWHERE  enex_master.ema_date = '2023-07-12'\\n   and enex_border.ebo_type = 2;\\n```\"]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831dba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
